{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFrost module loaded!\n",
      "Scan:\n",
      "  Kernel count: 5\n",
      "  Intermediate buffers: 0\n",
      "  Host readbacks: 0\n",
      "  Host writes: 0\n",
      "  Lines of generated code: 493\n",
      "  IR Compile time: 5.439100 ms\n",
      "  Steps time: 1511.394409 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import TensorFrost as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.initialize(tf.opengl)\n",
    "\n",
    "test_axis = 1\n",
    "\n",
    "def PrefixSum(A, axis = -1):\n",
    "    axis = len(A.shape) + axis if axis < 0 else axis\n",
    "    group_size = 128\n",
    "    grouped = tf.split_dim(A, group_size, axis)\n",
    "    group_scan = tf.prefix_sum(tf.sum(grouped, axis = axis + 1), axis = axis)\n",
    "    ids = grouped.indices\n",
    "    gid, eid = ids[axis], ids[axis + 1]\n",
    "    ids = [ids[i] for i in range(len(ids)) if i != axis + 1]\n",
    "    ids[axis] = gid - 1\n",
    "    group_scan = tf.prefix_sum(grouped + tf.select((gid == 0) | (eid != 0), 0, group_scan[tuple(ids)]), axis = axis + 1)\n",
    "    full_scan = tf.merge_dim(group_scan, target_size = A.shape[axis], axis = axis + 1)\n",
    "    return full_scan\n",
    "\n",
    "def Scan():\n",
    "    data = tf.input([-1, -1, -1], tf.int32)\n",
    "    return PrefixSum(data, axis = test_axis)\n",
    "\n",
    "scan_program = tf.compile(Scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  0\n",
      "Data:  [1 9 2 2 5 6 2 2 3 5 3 0 1 7 6 6 6 5 5 5 6 7 9 5 5]\n",
      "Grouped Scan:  [  1  10  12  14  19  25  27  29  32  37  40  40  41  48  54  60  66  71\n",
      "  76  81  87  94 103 108 113]\n",
      "Grouped Scan:  [  1  10  12  14  19  25  27  29  32  37  40  40  41  48  54  60  66  71\n",
      "  76  81  87  94 103 108 113 113 113 113 113 113 113 113]\n",
      "Grouped Scan:  [  1  10  12  14  19  25  27  29  32  37  40  40  41  48  54  60  66  71\n",
      "  76  81  87  94 103 108 113]\n",
      "Grouped:  [1 9 2 2 5 6 2 2 3 5 3 0 1 7 6 6 6 5 5 5 6 7 9 5 5 0 0 0 0 0 0 0]\n",
      "Grouped Scan1:  [ 29  60 108 113]\n",
      "Full Scan:  [  1  10  12  14  19  25  27  29  32  37  40  40  41  48  54  60  66  71\n",
      "  76  81  87  94 103 108 113]\n",
      "Sums:  [29 31 48  5]\n",
      "Diff:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate some random data to scan (ints between 0 and 10)\n",
    "data = np.random.randint(0, 10, (25, 1), dtype=np.int32)\n",
    "\n",
    "data_tf = tf.tensor(data)\n",
    "scan_tf, grouped, group_scan1, group_scan, sums = scan_program(data_tf)\n",
    "\n",
    "# do scan in numpy\n",
    "scan_np = np.cumsum(data, axis=test_axis)\n",
    "\n",
    "#print error\n",
    "print(\"Error: \", np.max(np.abs(scan_tf.numpy - scan_np)))\n",
    "\n",
    "print(\"Data: \", data.flatten())\n",
    "print(\"Grouped Scan: \", scan_np.flatten())\n",
    "print(\"Grouped Scan: \", group_scan.numpy.flatten())\n",
    "print(\"Grouped Scan: \", scan_tf.numpy.flatten())\n",
    "print(\"Grouped: \", grouped.numpy.flatten())\n",
    "print(\"Grouped Scan1: \", group_scan1.numpy.flatten())\n",
    "print(\"Full Scan: \", scan_tf.numpy.flatten())\n",
    "print(\"Sums: \", sums.numpy.flatten())\n",
    "print(\"Diff: \", np.abs(scan_tf.numpy - scan_np).flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
