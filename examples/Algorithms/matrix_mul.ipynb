{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFrost module loaded!\n",
      "matmul:\n",
      "  Kernel count: 1\n",
      "  Intermediate buffers: 0\n",
      "  Host readbacks: 0\n",
      "  Host writes: 0\n",
      "  Lines of generated code: 483\n",
      "  IR Compile time: 2.130800 ms\n",
      "  Steps time: 1552.213257 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import TensorFrost as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tf.initialize(tf.cpu)\n",
    "\n",
    "def matmul():\n",
    "    A = tf.input([-1, -1], tf.float32)\n",
    "    N, M = A.shape\n",
    "    B = tf.input([M,  -1], tf.float32)\n",
    "    K = B.shape[1]\n",
    "\n",
    "    #C = (tf.sin(A) @ tf.cos(B))**2.0\n",
    "\n",
    "    i,j,k = tf.indices([N, K, M])\n",
    "    C = tf.sum(tf.sin(A[i, k]) * tf.cos(B[k, j]))**2.0\n",
    "    return C\n",
    "\n",
    "mmul = tf.compile(matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated kernels:\n",
      "(('\\n#version 460\\n\\nuint pcg(uint v) {\\n  uint state = v * 747796405u + 2891336453u;\\n  uint word = ((state >> ((state >> 28u) + 4u)) ^ state) * 277803737u;\\n  return (word >> 22u) ^ word;\\n}\\n\\nfloat pcgf(uint v) {\\n  return float(pcg(v)) / float(0xffffffffu);\\n}\\n\\nfloat asfloat(uint x) {\\n  return uintBitsToFloat(x);\\n}\\n\\nuint asuint(float x) {\\n  return floatBitsToUint(x);\\n}\\n\\nuint asuint(bool x) {\\n\\treturn uint(x);\\n}\\n\\nuint asuint(int x) {\\n  return uint(x);\\n}\\n\\nuint asuint(uint x) {\\n  return x;\\n}\\n\\nint asint(uint x) {\\n  return int(x);\\n}\\n\\nbool asbool(uint x) {\\n  return bool(x);\\n}\\n\\n\\nstruct UBO {\\n  int K;\\n  int N;\\n  int M;\\n};\\n\\n', 'layout(std430, binding = 0) buffer buf_m0 {\\n  uint m0_mem[];\\n};\\n\\nfloat atomicAdd_m0(int index, float val) {\\n\\tuint uval = floatBitsToUint(val);\\n\\tuint tmp0 = 0;\\n\\tuint tmp1 = 0;\\n\\n\\twhile (true) {\\n\\t\\ttmp0 = atomicCompSwap(m0_mem[index], tmp1, uval);\\n\\t\\tif (tmp1 == tmp0) break;\\n\\t\\ttmp1 = tmp0;\\n\\t\\tuval = floatBitsToUint(val + uintBitsToFloat(tmp1));\\n\\t}\\n\\n\\treturn uintBitsToFloat(tmp1);\\n}\\n\\nlayout(std430, binding = 1) buffer buf_A {\\n  uint A_mem[];\\n};\\n\\nfloat atomicAdd_A(int index, float val) {\\n\\tuint uval = floatBitsToUint(val);\\n\\tuint tmp0 = 0;\\n\\tuint tmp1 = 0;\\n\\n\\twhile (true) {\\n\\t\\ttmp0 = atomicCompSwap(A_mem[index], tmp1, uval);\\n\\t\\tif (tmp1 == tmp0) break;\\n\\t\\ttmp1 = tmp0;\\n\\t\\tuval = floatBitsToUint(val + uintBitsToFloat(tmp1));\\n\\t}\\n\\n\\treturn uintBitsToFloat(tmp1);\\n}\\n\\nlayout(std430, binding = 2) buffer buf_B {\\n  uint B_mem[];\\n};\\n\\nfloat atomicAdd_B(int index, float val) {\\n\\tuint uval = floatBitsToUint(val);\\n\\tuint tmp0 = 0;\\n\\tuint tmp1 = 0;\\n\\n\\twhile (true) {\\n\\t\\ttmp0 = atomicCompSwap(B_mem[index], tmp1, uval);\\n\\t\\tif (tmp1 == tmp0) break;\\n\\t\\ttmp1 = tmp0;\\n\\t\\tuval = floatBitsToUint(val + uintBitsToFloat(tmp1));\\n\\t}\\n\\n\\treturn uintBitsToFloat(tmp1);\\n}\\n\\n\\nlayout(std140) uniform UBOBlock {\\n  UBO var;\\n};\\n\\n', 'layout (local_size_x = 16, local_size_y = 16, local_size_z = 1) in;\\n\\nvoid main() {\\n  int block_id = int(gl_WorkGroupID.x);\\n  int block_thread_id0 = int(gl_LocalInvocationID.x);\\n  int block_thread_id1 = int(gl_LocalInvocationID.y);\\n  int block_thread_id2 = int(gl_LocalInvocationID.z);\\n\\n  int blocks_shape_0 = ((var.K + 16) - 1) / 16;\\n  int v2_8 = block_id / blocks_shape_0;\\n  int index_0 = ((block_id - (v2_8 * blocks_shape_0)) * 16) + block_thread_id0;\\n  int index_1 = (v2_8 * 16) + block_thread_id1;\\n  bool is_inside_dispatch = (index_0 < var.K) && (index_1 < var.N);\\n  if (is_inside_dispatch)\\n  {\\n    float sum = 0.0f;\\n    for (int v3_2 = 0; v3_2 < var.M; v3_2 += 1)\\n    {\\n      float A = asfloat(A_mem[(clamp(index_1, 0, var.N - 1) * var.M) + clamp(v3_2, 0, var.M - 1)]);\\n      float B = asfloat(B_mem[(clamp(v3_2, 0, var.M - 1) * var.K) + clamp(index_0, 0, var.K - 1)]);\\n      sum = sum + (sin(A) * cos(B));\\n    }\\n    m0_mem[(index_1 * var.K) + index_0] = asuint(pow(sum, 2.0f));\\n  }\\n}\\n'), [('m0_mem', 'uint'), ('A_mem', 'uint'), ('B_mem', 'uint')])\n"
     ]
    }
   ],
   "source": [
    "all_kernels = tf.get_all_generated_kernels()\n",
    "print(\"Generated kernels:\")\n",
    "for k in all_kernels:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2.0039124e-06\n",
      "TF Time: 0.09612501412630081\n",
      "NP Time: 0.392515629529953\n",
      "Speedup: 4.083386963295713\n",
      "TF GFLOPS: 1429.793844206003\n",
      "NP GFLOPS: 350.1489956886213\n"
     ]
    }
   ],
   "source": [
    "Anp = np.random.rand(4096, 4096).astype(np.float32)\n",
    "Bnp = np.random.rand(4096, 4096).astype(np.float32)\n",
    "A = tf.tensor(Anp)\n",
    "B = tf.tensor(Bnp)\n",
    "\n",
    "start = time.time()\n",
    "repeat = 32\n",
    "for i in range(repeat):\n",
    "    C = mmul(A, B)\n",
    "Cnp = C.numpy\n",
    "tf_time = (time.time() - start) / repeat\n",
    "\n",
    "\n",
    "#compare to numpy\n",
    "start = time.time()\n",
    "for i in range(repeat):\n",
    "    Cnp2 = (np.sin(Anp) @ np.cos(Bnp))**2.0\n",
    "np_time = (time.time() - start) / repeat\n",
    "\n",
    "Cerror = np.linalg.norm(Cnp - Cnp2) / np.linalg.norm(Cnp2)\n",
    "print(\"Error:\", Cerror)\n",
    "print(\"TF Time:\", tf_time)\n",
    "print(\"NP Time:\", np_time)\n",
    "print(\"Speedup:\", np_time / tf_time)\n",
    "\n",
    "tf_flops = 2 * Anp.shape[0] * Anp.shape[1] * Bnp.shape[1] / tf_time\n",
    "print(\"TF GFLOPS:\", tf_flops / 1e9)\n",
    "np_flops = 2 * Anp.shape[0] * Anp.shape[1] * Bnp.shape[1] / np_time\n",
    "print(\"NP GFLOPS:\", np_flops / 1e9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
