{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFrost module loaded!\n",
      "matmul:\n",
      "  Kernel count: 1\n",
      "  Intermediate buffers: 0\n",
      "  Host readbacks: 0\n",
      "  Host writes: 0\n",
      "  Lines of generated code: 424\n",
      "  IR Compile time: 0.944300 ms\n",
      "  Compiler time: 1385.295044 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import TensorFrost as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tf.initialize(tf.opengl)\n",
    "\n",
    "def matmul():\n",
    "    A = tf.input([-1, -1], tf.float32)\n",
    "    N, M = A.shape\n",
    "    B = tf.input([M,  -1], tf.float32)\n",
    "    K = B.shape[1]\n",
    "\n",
    "    C = (tf.sin(A) @ tf.cos(B))**2.0\n",
    "\n",
    "    return [C]\n",
    "\n",
    "mmul = tf.compile(matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated kernels:\n",
      "\n",
      "#version 460\n",
      "\n",
      "uint pcg(uint v) {\n",
      "  uint state = v * 747796405u + 2891336453u;\n",
      "  uint word = ((state >> ((state >> 28u) + 4u)) ^ state) * 277803737u;\n",
      "  return (word >> 22u) ^ word;\n",
      "}\n",
      "\n",
      "float pcgf(uint v) {\n",
      "  return float(pcg(v)) / float(0xffffffffu);\n",
      "}\n",
      "\n",
      "float asfloat(uint x) {\n",
      "  return uintBitsToFloat(x);\n",
      "}\n",
      "\n",
      "uint asuint(float x) {\n",
      "  return floatBitsToUint(x);\n",
      "}\n",
      "\n",
      "uint asuint(int x) {\n",
      "  return uint(x);\n",
      "}\n",
      "\n",
      "uint asuint(uint x) {\n",
      "  return x;\n",
      "}\n",
      "\n",
      "int asint(uint x) {\n",
      "  return int(x);\n",
      "}\n",
      "\n",
      "uniform int var[32];\n",
      "layout(std430, binding = 0) buffer buf_A {\n",
      "  uint A_mem[];\n",
      "};\n",
      "\n",
      "float atomicAdd_A(int index, float val) {\n",
      "\tuint uval = floatBitsToUint(val);\n",
      "\tuint tmp0 = 0;\n",
      "\tuint tmp1 = 0;\n",
      "\n",
      "\twhile (true) {\n",
      "\t\ttmp0 = atomicCompSwap(A_mem[index], tmp1, uval);\n",
      "\t\tif (tmp1 == tmp0) break;\n",
      "\t\ttmp1 = tmp0;\n",
      "\t\tuval = floatBitsToUint(val + uintBitsToFloat(tmp1));\n",
      "\t}\n",
      "\n",
      "\treturn uintBitsToFloat(tmp1);\n",
      "}\n",
      "\n",
      "layout(std430, binding = 1) buffer buf_B {\n",
      "  uint B_mem[];\n",
      "};\n",
      "\n",
      "float atomicAdd_B(int index, float val) {\n",
      "\tuint uval = floatBitsToUint(val);\n",
      "\tuint tmp0 = 0;\n",
      "\tuint tmp1 = 0;\n",
      "\n",
      "\twhile (true) {\n",
      "\t\ttmp0 = atomicCompSwap(B_mem[index], tmp1, uval);\n",
      "\t\tif (tmp1 == tmp0) break;\n",
      "\t\ttmp1 = tmp0;\n",
      "\t\tuval = floatBitsToUint(val + uintBitsToFloat(tmp1));\n",
      "\t}\n",
      "\n",
      "\treturn uintBitsToFloat(tmp1);\n",
      "}\n",
      "\n",
      "layout(std430, binding = 2) buffer buf_m0 {\n",
      "  uint m0_mem[];\n",
      "};\n",
      "\n",
      "float atomicAdd_m0(int index, float val) {\n",
      "\tuint uval = floatBitsToUint(val);\n",
      "\tuint tmp0 = 0;\n",
      "\tuint tmp1 = 0;\n",
      "\n",
      "\twhile (true) {\n",
      "\t\ttmp0 = atomicCompSwap(m0_mem[index], tmp1, uval);\n",
      "\t\tif (tmp1 == tmp0) break;\n",
      "\t\ttmp1 = tmp0;\n",
      "\t\tuval = floatBitsToUint(val + uintBitsToFloat(tmp1));\n",
      "\t}\n",
      "\n",
      "\treturn uintBitsToFloat(tmp1);\n",
      "}\n",
      "\n",
      "layout (local_size_x = 16, local_size_y = 16, local_size_z = 1) in;\n",
      "\n",
      "void main() {\n",
      "  int block_id = int(gl_WorkGroupID.x);\n",
      "  int block_thread_id0 = int(gl_LocalInvocationID.x);\n",
      "  int block_thread_id1 = int(gl_LocalInvocationID.y);\n",
      "  int block_thread_id2 = int(gl_LocalInvocationID.z);\n",
      "\n",
      "  int blocks_shape_1 = ((asint(var[0]) + 16) - 1) / 16;\n",
      "  int v2_8 = block_id / blocks_shape_1;\n",
      "  int index_0 = (v2_8 * 16) + block_thread_id1;\n",
      "  int index_1 = ((block_id - (v2_8 * blocks_shape_1)) * 16) + block_thread_id0;\n",
      "  bool is_inside_dispatch = (index_0 < asint(var[1])) && (index_1 < asint(var[0]));\n",
      "  if (is_inside_dispatch)\n",
      "  {\n",
      "    float matmul = 0.0f;\n",
      "    for (int v3_2 = 0; v3_2 < asint(var[2]); v3_2 += 1)\n",
      "    {\n",
      "      float A = asfloat(A_mem[(index_0 * asint(var[2])) + v3_2]); // A\n",
      "      float B = asfloat(B_mem[(v3_2 * asint(var[0])) + index_1]); // B\n",
      "      matmul = matmul + (sin(A) * cos(B));\n",
      "    }\n",
      "    m0_mem[(index_0 * asint(var[0])) + index_1] = asuint(pow(matmul, 2.0f)); // m0\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_kernels = tf.get_all_generated_kernels()\n",
    "print(\"Generated kernels:\")\n",
    "for k in all_kernels:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2.0023163e-06\n",
      "TF Time: 0.09573355436325073\n",
      "NP Time: 0.37513524055480957\n",
      "Speedup: 3.9185345519649153\n",
      "TF GFLOPS: 1435.6403497827166\n",
      "NP GFLOPS: 366.37174707642356\n"
     ]
    }
   ],
   "source": [
    "Anp = np.random.rand(4096, 4096).astype(np.float32)\n",
    "Bnp = np.random.rand(4096, 4096).astype(np.float32)\n",
    "A = tf.tensor(Anp)\n",
    "B = tf.tensor(Bnp)\n",
    "\n",
    "start = time.time()\n",
    "repeat = 100\n",
    "for i in range(repeat):\n",
    "    C, = mmul(A, B)\n",
    "Cnp = C.numpy\n",
    "tf_time = (time.time() - start) / repeat\n",
    "\n",
    "\n",
    "#compare to numpy\n",
    "start = time.time()\n",
    "for i in range(repeat):\n",
    "    Cnp2 = (np.sin(Anp) @ np.cos(Bnp))**2.0\n",
    "np_time = (time.time() - start) / repeat\n",
    "\n",
    "Cerror = np.linalg.norm(Cnp - Cnp2) / np.linalg.norm(Cnp2)\n",
    "print(\"Error:\", Cerror)\n",
    "print(\"TF Time:\", tf_time)\n",
    "print(\"NP Time:\", np_time)\n",
    "print(\"Speedup:\", np_time / tf_time)\n",
    "\n",
    "tf_flops = 2 * Anp.shape[0] * Anp.shape[1] * Bnp.shape[1] / tf_time\n",
    "print(\"TF GFLOPS:\", tf_flops / 1e9)\n",
    "np_flops = 2 * Anp.shape[0] * Anp.shape[1] * Bnp.shape[1] / np_time\n",
    "print(\"NP GFLOPS:\", np_flops / 1e9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
